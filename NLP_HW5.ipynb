{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled20.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMgLS_zxiNEA",
        "outputId": "824e5c33-445c-42d3-c198-8ed82c3a40f7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv78k98v0HMK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45363a69-50aa-40be-e793-6b7c24edbb85"
      },
      "source": [
        "from __future__ import print_function\n",
        "import json \n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense\n",
        "import numpy as np\n",
        "\n",
        "# 參數設定\n",
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 100  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
        "num_samples = 10000  # Number of samples to train on.\n",
        "\n",
        "\n",
        "def readdata():\n",
        "    input_texts = []\n",
        "    target_texts = []\n",
        "    input_characters = set()\n",
        "    target_characters = set()\n",
        "    with open('/content/drive/MyDrive/translation2019zh_train.json', 'r', encoding='utf-8-sig') as f:\n",
        "        words = f.readlines()\n",
        "        for i, text in enumerate(words):\n",
        "            if i>1000:\n",
        "                break\n",
        "            js = json.loads(text)\n",
        "            input_text = js[\"english\"]\n",
        "            target_text = '\\t' + js[\"chinese\"] + '\\n'\n",
        "            input_texts.append(input_text)\n",
        "            target_texts.append(target_text)\n",
        "            for char in input_text:\n",
        "                if char not in input_characters:\n",
        "                    input_characters.add(char)\n",
        "            for char in target_text:\n",
        "                if char not in target_characters:\n",
        "                    target_characters.add(char)\n",
        "    return input_texts,target_texts,input_characters,target_characters\n",
        "\n",
        "input_texts,target_texts,input_characters,target_characters = readdata()\n",
        "          \n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "# 計算編碼器、解碼器的最大長度\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print('Number of samples:', len(input_texts))\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 1001\n",
            "Number of unique input tokens: 129\n",
            "Number of unique output tokens: 2410\n",
            "Max sequence length for inputs: 232\n",
            "Max sequence length for outputs: 122\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwFF2TsR0qcX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a223ef14-bab3-401d-e9d3-bae5f7d8035f"
      },
      "source": [
        "# 以dict儲存字典單字及序號\n",
        "input_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "(len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "(len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "(len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "dtype='float32')\n",
        "\n",
        "# 設定 encoder_input、decoder_input對應的順序    \n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
        "\n",
        "# 建立 encoder LSTM 隱藏層\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "# 捨棄 output，只保留記憶狀態 h 及 c\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# 建立 decoder LSTM 隱藏層\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "# We set up our decoder to return full output sequences,\n",
        "# decoder 記憶狀態不會在訓練過程使用，只會在推論(Inference)使用\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# 定義模型，由 encoder_input_data 及 decoder_input_data 轉換為 decoder_target_data \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# 訓練\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.2)\n",
        "          \n",
        "          \n",
        "# 儲存模型及結果\n",
        "model.save('s2s.h5')\n",
        "\n",
        "# 推論(Inference)\n",
        "# 過程如下:\n",
        "# 1) encode input and retrieve initial decoder state\n",
        "# 2) run one step of decoder with this initial state\n",
        "# and a \"start of sequence\" token as target.\n",
        "# Output will be the next target token\n",
        "# 3) Repeat with the current target token and current states\n",
        "\n",
        "# 定義編碼器取樣模型\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# 定義解碼器的input\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# 定義解碼器 LSTM 模型\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "    \n",
        "# 以編碼器的記憶狀態 h 及 c 為解碼器的記憶狀態  \n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n",
        "\n",
        "# 建立反向的 dict，才能透過查詢將數值轉回文字\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 8s 387ms/step - loss: 2.1312 - val_loss: 2.0150\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 3s 262ms/step - loss: 2.0141 - val_loss: 2.0097\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 3s 269ms/step - loss: 2.0076 - val_loss: 2.0082\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 3s 266ms/step - loss: 2.0046 - val_loss: 2.0076\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 3s 263ms/step - loss: 2.0022 - val_loss: 2.0057\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 3s 265ms/step - loss: 2.0003 - val_loss: 2.0042\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 3s 262ms/step - loss: 1.9986 - val_loss: 2.0029\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 3s 266ms/step - loss: 1.9975 - val_loss: 2.0031\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 3s 264ms/step - loss: 1.9961 - val_loss: 2.0021\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 3s 261ms/step - loss: 1.9951 - val_loss: 2.0057\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 3s 262ms/step - loss: 1.9951 - val_loss: 2.0049\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 3s 264ms/step - loss: 1.9943 - val_loss: 2.0051\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 3s 261ms/step - loss: 1.9939 - val_loss: 2.0051\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 3s 264ms/step - loss: 1.9929 - val_loss: 2.0063\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 3s 266ms/step - loss: 1.9927 - val_loss: 2.0066\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 3s 263ms/step - loss: 1.9922 - val_loss: 2.0062\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 3s 267ms/step - loss: 1.9926 - val_loss: 2.0037\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 3s 261ms/step - loss: 1.9911 - val_loss: 2.0051\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 3s 263ms/step - loss: 1.9909 - val_loss: 2.0061\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 3s 265ms/step - loss: 1.9906 - val_loss: 2.0060\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 3s 266ms/step - loss: 1.9903 - val_loss: 2.0088\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 3s 265ms/step - loss: 1.9900 - val_loss: 2.0077\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 3s 261ms/step - loss: 1.9896 - val_loss: 2.0091\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 3s 267ms/step - loss: 1.9894 - val_loss: 2.0085\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 3s 266ms/step - loss: 1.9885 - val_loss: 2.0110\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 3s 262ms/step - loss: 1.9892 - val_loss: 2.0101\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 3s 263ms/step - loss: 1.9884 - val_loss: 2.0106\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 3s 259ms/step - loss: 1.9876 - val_loss: 2.0146\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 3s 264ms/step - loss: 1.9888 - val_loss: 2.0094\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 3s 264ms/step - loss: 1.9871 - val_loss: 2.0101\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 3s 265ms/step - loss: 1.9861 - val_loss: 2.0117\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 3s 267ms/step - loss: 1.9868 - val_loss: 2.0126\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 3s 265ms/step - loss: 1.9862 - val_loss: 2.0118\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 3s 264ms/step - loss: 1.9860 - val_loss: 2.0132\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 3s 263ms/step - loss: 1.9851 - val_loss: 2.0164\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 3s 264ms/step - loss: 1.9856 - val_loss: 2.0155\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 3s 263ms/step - loss: 1.9857 - val_loss: 2.0143\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 3s 269ms/step - loss: 1.9848 - val_loss: 2.0127\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 3s 262ms/step - loss: 1.9840 - val_loss: 2.0146\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 3s 262ms/step - loss: 1.9835 - val_loss: 2.0169\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 3s 267ms/step - loss: 1.9841 - val_loss: 2.0137\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 3s 264ms/step - loss: 1.9831 - val_loss: 2.0151\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 3s 261ms/step - loss: 1.9833 - val_loss: 2.0139\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 3s 267ms/step - loss: 1.9824 - val_loss: 2.0165\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 3s 260ms/step - loss: 1.9822 - val_loss: 2.0176\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 3s 261ms/step - loss: 1.9826 - val_loss: 2.0144\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 3s 263ms/step - loss: 1.9819 - val_loss: 2.0198\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 3s 261ms/step - loss: 1.9826 - val_loss: 2.0196\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 3s 263ms/step - loss: 1.9821 - val_loss: 2.0167\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 3s 260ms/step - loss: 1.9816 - val_loss: 2.0187\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 3s 267ms/step - loss: 1.9806 - val_loss: 2.0185\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 3s 263ms/step - loss: 1.9810 - val_loss: 2.0181\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 3s 263ms/step - loss: 1.9799 - val_loss: 2.0199\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 3s 267ms/step - loss: 1.9809 - val_loss: 2.0218\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 3s 263ms/step - loss: 1.9805 - val_loss: 2.0198\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 3s 264ms/step - loss: 1.9800 - val_loss: 2.0203\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 3s 264ms/step - loss: 1.9799 - val_loss: 2.0183\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 3s 265ms/step - loss: 1.9794 - val_loss: 2.0194\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 3s 265ms/step - loss: 1.9785 - val_loss: 2.0182\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 3s 261ms/step - loss: 1.9783 - val_loss: 2.0216\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 3s 264ms/step - loss: 1.9785 - val_loss: 2.0209\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 3s 260ms/step - loss: 1.9791 - val_loss: 2.0211\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 3s 264ms/step - loss: 1.9788 - val_loss: 2.0234\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 3s 262ms/step - loss: 1.9782 - val_loss: 2.0206\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 3s 264ms/step - loss: 1.9780 - val_loss: 2.0206\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 3s 267ms/step - loss: 1.9771 - val_loss: 2.0224\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 3s 261ms/step - loss: 1.9785 - val_loss: 2.0219\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 3s 266ms/step - loss: 1.9765 - val_loss: 2.0241\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 3s 257ms/step - loss: 1.9769 - val_loss: 2.0240\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 3s 261ms/step - loss: 1.9768 - val_loss: 2.0228\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 3s 260ms/step - loss: 1.9767 - val_loss: 2.0244\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 3s 263ms/step - loss: 1.9769 - val_loss: 2.0243\n",
            "Epoch 73/100\n",
            "13/13 [==============================] - 3s 264ms/step - loss: 1.9764 - val_loss: 2.0237\n",
            "Epoch 74/100\n",
            "13/13 [==============================] - 3s 266ms/step - loss: 1.9760 - val_loss: 2.0233\n",
            "Epoch 75/100\n",
            "13/13 [==============================] - 3s 266ms/step - loss: 1.9762 - val_loss: 2.0259\n",
            "Epoch 76/100\n",
            "13/13 [==============================] - 3s 264ms/step - loss: 1.9758 - val_loss: 2.0246\n",
            "Epoch 77/100\n",
            "13/13 [==============================] - 3s 265ms/step - loss: 1.9745 - val_loss: 2.0278\n",
            "Epoch 78/100\n",
            "13/13 [==============================] - 3s 262ms/step - loss: 1.9775 - val_loss: 2.0248\n",
            "Epoch 79/100\n",
            "13/13 [==============================] - 3s 265ms/step - loss: 1.9743 - val_loss: 2.0243\n",
            "Epoch 80/100\n",
            "13/13 [==============================] - 3s 260ms/step - loss: 1.9753 - val_loss: 2.0232\n",
            "Epoch 81/100\n",
            "13/13 [==============================] - 3s 261ms/step - loss: 1.9739 - val_loss: 2.0253\n",
            "Epoch 82/100\n",
            "13/13 [==============================] - 3s 266ms/step - loss: 1.9757 - val_loss: 2.0243\n",
            "Epoch 83/100\n",
            "13/13 [==============================] - 3s 265ms/step - loss: 1.9735 - val_loss: 2.0283\n",
            "Epoch 84/100\n",
            "13/13 [==============================] - 3s 267ms/step - loss: 1.9732 - val_loss: 2.0262\n",
            "Epoch 85/100\n",
            "13/13 [==============================] - 3s 259ms/step - loss: 1.9733 - val_loss: 2.0257\n",
            "Epoch 86/100\n",
            "13/13 [==============================] - 3s 265ms/step - loss: 1.9735 - val_loss: 2.0244\n",
            "Epoch 87/100\n",
            "13/13 [==============================] - 3s 259ms/step - loss: 1.9739 - val_loss: 2.0260\n",
            "Epoch 88/100\n",
            "13/13 [==============================] - 3s 259ms/step - loss: 1.9727 - val_loss: 2.0285\n",
            "Epoch 89/100\n",
            "13/13 [==============================] - 3s 260ms/step - loss: 1.9727 - val_loss: 2.0258\n",
            "Epoch 90/100\n",
            "13/13 [==============================] - 3s 268ms/step - loss: 1.9756 - val_loss: 2.0282\n",
            "Epoch 91/100\n",
            "13/13 [==============================] - 3s 265ms/step - loss: 1.9754 - val_loss: 2.0245\n",
            "Epoch 92/100\n",
            "13/13 [==============================] - 3s 260ms/step - loss: 1.9732 - val_loss: 2.0247\n",
            "Epoch 93/100\n",
            "13/13 [==============================] - 3s 261ms/step - loss: 1.9723 - val_loss: 2.0257\n",
            "Epoch 94/100\n",
            "13/13 [==============================] - 3s 266ms/step - loss: 1.9718 - val_loss: 2.0267\n",
            "Epoch 95/100\n",
            "13/13 [==============================] - 3s 265ms/step - loss: 1.9717 - val_loss: 2.0282\n",
            "Epoch 96/100\n",
            "13/13 [==============================] - 3s 263ms/step - loss: 1.9708 - val_loss: 2.0289\n",
            "Epoch 97/100\n",
            "13/13 [==============================] - 3s 261ms/step - loss: 1.9730 - val_loss: 2.0269\n",
            "Epoch 98/100\n",
            "13/13 [==============================] - 3s 261ms/step - loss: 1.9710 - val_loss: 2.0280\n",
            "Epoch 99/100\n",
            "13/13 [==============================] - 3s 265ms/step - loss: 1.9722 - val_loss: 2.0273\n",
            "Epoch 100/100\n",
            "13/13 [==============================] - 3s 260ms/step - loss: 1.9701 - val_loss: 2.0277\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1RUWpKgGA_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d648db0a-2c90-45d6-caea-4f608dfeecec"
      },
      "source": [
        "# 模型預測，並取得翻譯結果(中文)    \n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "# 測試100次\n",
        "for seq_index in range(100):\n",
        "    # Take one sequence (part of the training test)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('*')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    try:\n",
        "        print('Decoded sentence:', decoded_sentence)\n",
        "    except:\n",
        "        # 出現亂碼，以?取代\n",
        "        print('Decoded sentence:', decoded_sentence.encode('ascii', 'replace'))\n",
        "        #print(\"error:\", sys.exc_info()[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*\n",
            "Input sentence: For greater sharpness, but with a slight increase in graininess, you can use a 1:1 dilution of this developer.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: He calls the Green Book, his book of teachings, “the new gospel.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: And the light breeze moves me to caress her long ear\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: They have the blood of martyrs is the White to flow …\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Finally, the Lakers head to the Motor City to take on a Pistons team that currently owns the Eastern Conference's second best record (1/31). L.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: \"The perfect match—my father loves names and Jackie loves money, \" sneered Alexander at the wedding. Neither he nor Christina ever got along with their stepmother17.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: In 2006, Walmart was charged with racism when its recommendation engine paired Planet of the Apes with a documentary about Martin Luther King.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: The matte as main copper phase in the cleaning. slag was deter- mined by electron probe microscopic analysis.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Have you shined your shoes?\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: The Tanning Matrix can be formed by resorcinol and oxazolidine E, and the reactioncharateristics between Tanning Matrix and collagen were investigated through NMR and size distribution analysis.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Free delivery for addresses in the city. Can be delivered through Internet.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Keele University is renowned for its exciting approach to higher education, beautiful campus, strong community spirit and excellent student life.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Among them, there was the herb Tuckahoe grown in Yunnan and Guizhou provinces.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Your willingness to sacrifice countless late nights consoling them?\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Callum: OK, we'll find out if you're right at the end of the programme.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: When standing on a level surface, the hind feet are set back from under the body and the leg from pad to hock is at right angles to the ground.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: So who won? (Alaska doesn't count, you BOUGHT that state from Russia.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: A Minneapolis couple decided to go to Florida to thaw out during a particularly icy winter.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Dumbledore, the lover of warm socks and sherbet lemons, creates soft, comfortable furniture.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: To escape with a Ph.D., you must meaningfully extend the boundary of human knowledge.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Barry had been D.C.'s mayor for 12 years before he was put into prison for involvement with drugs in 1990.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Phase out nankin/social security. It's not working and it's going to bankrupt the country.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Daniel Radcliffe, who plays Harry, thanked all the fans who had turned up. \"If this doesn't get you exhilarated, nothing else will,\" he said.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Look at these coasters over here.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: It was tight. so ti lasted a long time .\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: To use tone, press the YES button. You must use tone if you are setting up. the 2300 as a stand-alone stereo encoder.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Fuler is one of 253 schools have credited by the Sociation of Phiological schools in the United States and Canada.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: It shows that vertical stiffener's spaces have some effects on pure-shearing ulti…\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: \"People are embarrassed to admit that's why they're giving up their pets, \" said Betsy McFarland, the Humane Society's director of communications for companion animals.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Mars gets hit in this tutorial complete with monolith from 2001 Space Odyssey all in 2D.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Show all articles on this topic.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Yesterday, a city with the husband and wife suffering from AIDS in the city hospital to get two of their 18-month-old daughter of the AIDS antibody test results of the report alone.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: A model wearing a traditional Korean hanbok performs in a water tank at the \"Underwater Hanbok Fashion Show\" in Seoul, South Korea.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Haven't found some hurt you when it is not pain, you pay attention to it begins to faint do painful.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: First of all, the term \"justice\" can have different interpretations in language. That is, a language can define different connotations for \"justice.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Standard Edition: for small-scale applications that require data caching and sharing clustered data.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: So basically our L/Cs are no different then other sight L/Cs.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Through parameter calibration and model validation, model can be adapted to morphogenesis and LAI simulation for different varieties and management practice.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: NH3-N and concentration of particles reached lnd standard of sewage treatment plant.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Due to the high tonnage and large span of the whole steel space frame, process and fabrication of the steel space frame shall be strictly precise.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: As another example, the Japanese traditional \"soup\" (ie take a bath Church) is the mixing of men and women bath in some places so far, and often not prepared to foreigners, \"red in the face.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: The theme ofWWIIwill always remain actual as the war will always be remembered by off-springs of those who won it.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: No suspected cancer cells or cancer cells were found.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: As our quotation is based on sea extra charge for dispatch by parcel post should be borne by buyers.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Three bright spots , namely: China? Anping International Wire Mesh Fair, Anping international wire mesh Anping wire mesh industry base and the World.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: The ever-intensifying contradictions between economic development and resources and environment must be solved earnestly.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Still, who are we to say that we can stay?\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Then, in analogy with the annealing of metals, the temperature is made high in the early stages of the process for faster minimisation or learning, then is reduced for greater stability.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: In these few years, the vehicle are rapidly increasing, the different parking are becoming more and more outstanding. The automatic parking system would provide a good way to set down the problems.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Well my name is lee i am 30yrs my interest is movie, basketball, roller skating, shooting pool, bowling, music, & going on long walks in the park with my dog diamond.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: He had formerly been in business at Bristol, but failed in debt to a number of people, compounded, and went to America.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Basing on the on site tests of anchor, authors found that anchors have obvious pre stress loss problem during stretching and locking, analyzed and proposed several solutions.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: From hair tip first began gradually, after all, through from downward, nodular comb.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: The sky began to be clear up a bit when we left St Gallen abbey and library.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Once more, Cinderella's fairy godmother reminded her to be home by midnight.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: This paper introduces the demand analysis and function design in detail, gives the source codes of relevant interface functions and base algorithm.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Manufacturer of thin and ultra-thin non-ferrous metal foils mainly made of copper, copper-alloys, nickel, genuine silver and nickel-silver.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: All day thy wings have fann'd At that far height, the cold thin atmosphere: Yet stoop not, weary, to the welcome land, Though the dark night is near.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: The two other attackers are believed to have tried to enter the terminal, which is protected by heavily armed police and X-ray machines.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: He became in legitimately through the door of the Law (vv. 1-3).\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: The effect mechanism of laser biology was systemotically and deeply discussed in this artical, from 4 aspects:the light, electromagnetism field, heat and pressure effect of laser.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: The variant of FOXO3A associated with longevity is much more prevalent in 100-year-olds even than in 95-year-olds, which clearly demonstrates the value of studying the centenarian genome.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Again, Uruguay are slight exception – they did start with a three-man defence.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Rugby' Seven People System origined from Scotland, it has special regularity and character.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: This month you will be the darling of the media, so try to be a guest on TV and radio, or try for an interview or write-up on the Inte or in print.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: So Isay to you that a novel must stand up to the adult tests of reality.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Yeah, like gentle breeze blowing through the cheeks, the hair dancing in the wind.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: At present the direction of travel is not fully clear, but Theresa May's government has promised to set out a plan before triggering the EU's Article 50 divorce procedure.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Both the theoretical and experimental results have shown that there is a constant water level difference between the refined dynamic water level and the static one in the same well.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Otwoma believes the expense of generating nuclear energy could one day be met through shared regional projects but, until then, Kenya has to move forward on its own.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: On July 14, the Kremlin announced it will suspend participation in the Treaty on Conventional Forces in Europe, or CFE for short.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Outside-left. Made United debut at 17.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: When the soul descends it divides itself creating a male and female half-soul.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Axis symmetrical pure radial and pure shear vibrations were investigated theoretically for disk concentrators, whose thickness varying step-wise, linearly or exponentially with radial distance.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: The idea of flipping from one entry to another, following a line of inquiry (especially etymological inquiry) from one page to another, even one volume to another, is a sensual experience.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Further Practice for Pairs ·Add a third speaker and create your own lines.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Still, Brasier asserts that the light carbon enrichments may well be able to form through lifeless chemical reactions—much as Fedo and others have argued could have occurred at Akilia.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: The company is through ISO9001 quality system authentication , some products have also passed UL, CCEE authentication .\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: The Book of Revelation was also traditionally assigned to him.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Our guest bedroom has an entire wall stacked with boxes containing unknown objects of more “stuff”.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: It was easily good enough for pole so that was the main thing.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: This instrument uses the hardware structure taking 8031 chip-microprocessor as a main. It has functions of self-diagnosis, digital filtering and non-linear compensation etc.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: While these space rocks don't exactly share our planet's orbit, they do cross it, in the sense that when they are closest to the sun, they are inside Earth's orbital path.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: John has a windfall . It surprises his wife greatly .\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: So, the article researched the geography distribution of poets from 712AD to 805AD according to the fifteen Dao and analyzed the poets that existed in the same time and room.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Yet he's ready to move on, knowing that \"the causes I care about have campaign-tested technology to work with.\"\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Kandahar provincial official and his bodyguard on their way to work were shot dead by two gunmen on a motorbike.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: We've rounded up some unusual ways to put your bottom-shelf vodka to good use all around your house.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: The target of anti_monopoly law should be to contain monopolizing behavior and various restrictive practices.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: To build a conservation-minded society, we should act at present for our future.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Large doses of carbs, sugar, and caffeine might keep you awake for a short time, but they will eventually lead to a \"crash, \" and have the opposite effect.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: We desperately need a nation to exert some leadership, adopting policies to move promptly in that direction.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Environmental records shall be stored and maintained in such a way that they are readily retrievable and protected against damage, deterioration or loss.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: He hastily composed another post, and then spent twenty minutes rephrasing it in a calmer tone, but a day later, when that message had also been deleted, his rage erupted.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Results(1)Determining the morbidity of hyperbilirubinemia; It put up an extremely remarkable difference comparing the antibody-released test result being positive group to the control group(P<0.01).\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: All eastbound trains have been cancelled due to faulty signals.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Taken into account the fact that aggregates absorb pitch, required abilities to resist high temperature track and penetration could be gained by controlling interspace ratio (4%).\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Unlike many of the other pirate-radio operators, who were in it mostly for money or adventure, Smedley saw his broadcasts as part of a wider moral crusade.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Ran Hua (1961 ~), female, associate professor, PhD. candidate , School of Journalism & Communication, Wuhan University, majoring in communication theories.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "*\n",
            "Input sentence: Others include shrouding Earth in sun-reflecting aerosol particles, manufacturing CO2-absorbing artificial trees, and pumping CO2 into underground reservoirs.\n",
            "Decoded sentence: 我我，，，，，的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}